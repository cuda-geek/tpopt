<!doctype html>
<html lang="en">

    <head>
        <meta charset="utf-8">

        <title>Pragmatic optimization in modern programming</title>

        <meta name="description" content="Pragmatic optimization in modern programming">
        <meta name="author" content="geek">

        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

        <link rel="stylesheet" href="css/reveal.css">
        <link rel="stylesheet" href="css/theme/beige.css" id="theme">
        <link rel="stylesheet" href="css/customization.css">

        <!-- Code syntax highlighting -->
        <link rel="stylesheet" href="lib/css/zenburn.css">

        <!-- <link rel="shortcut icon" href="images/ico/favicon.ico"> -->

        <!-- Printing and PDF exports -->
        <script>
            var link = document.createElement( 'link' );
            link.rel = 'stylesheet';
            link.type = 'text/css';
            link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
            document.getElementsByTagName( 'head' )[0].appendChild( link );
        </script>

        <!--[if lt IE 9]>
        <script src="lib/js/html5shiv.js"></script>
        <![endif]-->
    </head>

  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <h1>Pragmatic optimization</h1>
          <h2>In modern programming</h2>
          <h3>Modern computer architecture concepts</h3>
          <p>
            <small>Created by
              <a href="https://github.com/cuda-geek">Marina (geek) Kolpakova</a>
              for
              <a href="unn.ru">UNN</a>
              / 2015-2016
            </small>
          </p>
        </section>

<!--         <section>
          <h2>Course Topics</h2>
          <ul>
            <li><strong>Pragmatics</strong>
              <ul>
                <li>Ordering optimization approaches</li>
                <li>Demystifying a compiler</li>
                <li style="margin-bottom: 20px;"><b>Mastering compiler optimizations</b></li>
              </ul>
            </li> -->
<!--             <li><strong>Computer Architectures</strong>
              <ul>
                <li>Modern architecture families</li>
                <li>Cache organization</li>
                <li style="margin-bottom: 20px;">Instruction scheduling</li>
              </ul>
            </li> -->
<!--             <li><strong>Advanced capabilities</strong>
              <ul>
                <li>SIMD extensions</li>
                <li>Specific co-processors</li>
              </ul>
            </li> -->
<!--           </ul>
        </section> -->

        <section>
          <h2>Outline</h2>
          <ul>
            <li>Three aspects of the computer architecture</li>
            <li>Latency vs Throughput architectures</li>
            <li>CISC</li>
            <li>RISC</li>
            <li>VLIW</li>
            <li>Vector</li>
            <li>Latest trends</li>
          </ul>
        </section>

        <section>
          <section>
            <h2>1-st Aspect of Computer Architecture</h2>
            <blockquote><b>Instruction Set Architecture or ISA (interface)</b><br>
            is a <strong>contract</strong> between HW and SW, which specifies<br> <strong>right</strong>,
              <strong>possibilities</strong> &amp; <strong>limitations</strong>.</blockquote>
            <ul>
              <li>Class of ISA (load-store, register-memory)</li>
              <li>Memory addressing modes &amp; rules (base-immediate, alignment requirements)</li>
              <li>Types &amp; sizes of operands (size of byte, short)</li>
              <li>Operations (general arithmetic, control, logical)</li>
              <li>Control flow instructions (branches, jumps, calls, returns)</li>
              <li>Encoding an ISA (fixed or variable length)</li>
              <li><i>All the conceptual aspects of the architecture</i></li>
            </ul>
          </section>
          <section>
            <h2>2-nd Aspect of Computer Architecture</h2>
            <blockquote><b>Microarchitecture (organization)</b>
            is a concrete implementation of the ISA, the high-level aspects of a processor design (memory system,
            memory interconnect, design of the processor internals).</blockquote>
            <ul>
              <li>Pipeline width</li>
              <li>Instruction latencies</li>
              <li>Issue wight and scheduling</li>
              <li>Speculation capabilities</li>
              <li><i>All the concrete aspects of the architecture</i></li>
            </ul>
          </section>
          <section>
            <h2>3-nd Aspect of Computer Architecture</h2>
            <blockquote><b>Hardware or chip (design)</b>
            is the specifics of a computer, including the logic design and packaging. This is a concrete
              implementation of the microarchitecture.</blockquote>
            <ul>
              <li>Tech-process</li>
              <li>Clock rates</li>
              <li>On die placement</li>
              <li>All the properties of the chip</li>
            </ul>
          </section>
        </section>

        <section>
          <section>
            <h2>Architecture: Armv8-a</h2>
              <table>
                <colgroup>
                  <col style="width: 25%"></col>
                  <col></col>
                  <col></col>
                </colgroup>
                <thead>
                  <tr>
                    <th>&mu;arch</th>
                    <th>IP</th>
                    <th>Hardware</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Cortex-A53</td>
                    <td>ARM</td>
                    <td>Octa Exynos 7(7580) 1.6GHz 28nm <abbr title="High-k Metal Gate">HKMG</abbr></td>
                  </tr>
                  <tr>
                    <td width="17%">Cortex-A57</td>
                    <td>ARM</td>
                    <td>Octa Exynos 7(7420) <small style="vertical-align:bottom; ">big.LITTLE</small>
                    2.1/1.5 14<abbr title="Fin-Shaped Field Effect Transistor">FF</abbr> (
                    <abbr title="Low power Early">LPE</abbr>) (Samsung)</td>
                  </tr>
                  <tr>
                    <td>Cortex-A72</td>
                    <td>ARM</td>
                    <td>Deca MediaTek Helio X20 <small style="vertical-align:bottom; ">big.LITTLE</small> 2.5/2.0/1.4
                    20<abbr title="High-k Metal Gate">HKMG</abbr> (TSMC)  </td>
                  </tr>
                  <tr>
                    <td>Cortex-A35</td>
                    <td>ARM</td>
                    <td></td>
                  </tr>
                </tbody>
              </table>
          </section>
          <section>
            <h2>Architecture: Armv8-a</h2>
              <table>
                <colgroup>
                  <col style="width: 25%"></col>
                  <col></col>
                  <col></col>
                </colgroup>
                <thead>
                  <tr>
                    <th>&mu;arch</th>
                    <th>IP</th>
                    <th>Hardware</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Denver</td>
                    <td>NVIDIA</td>
                    <td>Dual Tegra K1 2.3GHz 28nm <abbr title="High Performance Mobile">HPM</abbr></td>
                  </tr>
                  <tr>
                    <td>Kryo</td>
                    <td>Qualcomm</td>
                    <td>Tetra S820 <small style="vertical-align:bottom; ">big.LITTLE</small>
                    2.2/1.6GHz 14<abbr title="Fin-Shaped Field Effect Transistor">FF (LPP)</abbr> (Samsung)</td>
                  </tr>
                  <tr>
                    <td>Exynos M1</td>
                    <td>Samsung</td>
                    <td>Exynos 8890 (no details yet) </td>
                  </tr>
                </tbody>
              </table>
          </section>
          <section>
            <h2>Architecture: Armv8-a</h2>
              <table>
                <colgroup>
                  <col style="width: 25%"></col>
                  <col></col>
                  <col></col>
                </colgroup>
                <thead>
                  <tr>
                    <th>&mu;arch</th>
                    <th>IP</th>
                    <th>Hardware</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Cyclone</td>
                    <td>Apple</td>
                    <td>Dual A7 (APL0698) 1.4GHz 28nm <abbr title="High-k Metal Gate">HKMG</abbr> (Samsung)</td>
                  </tr>
                  <tr>
                    <td>Typhoon</td>
                    <td>Apple</td>
                    <td>Dual A8 (APL1012) 1.3GHz 20<abbr title="High-k Metal Gate">HKMG</abbr> (TSMC)</td>
                  </tr>
                  <tr>
                    <td style="border-bottom: none;" rowspan="2">Twister</td>
                    <td style="border-bottom: none;" rowspan="2">Apple</td>
                    <td>Dual A9 (APL0898) 1.85GHz 16<abbr title="Fin-Shaped Field Effect Transistor">FF+</abbr> (TSMC)</td>
                  </tr>
                  <tr >
                    <td>Dual A9 (APL1022) 1.85GHz 14<abbr title="Fin-Shaped Field Effect Transistor">FF</abbr>(
                    <abbr title="Low power Plus">LPP)</abbr> (Samsung)</td>
                  </tr>
                </tbody>
              </table>
          </section>
        </section>

        <section>
          <section>
            <h2>Latency <small style="vertical-align: bottom;">vs</small> Throughput architectures</h2>
            <dl>
              <dt><b>Latency</b> oriented architecture</dt>
              <dd>
                <ul>
                  <li><b>addresses latency hiding issues;</b></li>
                  <li>features sophisticated pipelining, out-of-order;</li>
                  <li>employs advanced cache hierarchies;</li>
                  <li>widely uses speculation.</li>
                  <li><b>Compute cores occupy only a small part of a die.</b></li>
                </ul>
              </dd>
            </dl>
          </section>
          <section>
            <h2>Latency <small style="vertical-align: bottom;">vs</small> Throughput architectures</h2>
            <dl>
              <dt><b>Throughput</b> oriented architecture</dt>
              <dd>
                <ul>
                  <li><b>performs a bunch of operations in fly;</b></li>
                  <li>features many simple compute units/cores;</li>
                  <li>employs simple pipelines to provide a low-cost thread scheduling;</li>
                  <li>uses wide basses, tiling, programmable local memory.</li>
                  <li><b>Compute cores occupy most part of a die.</b></li>
                </ul>
              </dd>
            </dl>
          </section>
        </section>
<!--
        <section>
          <h2>What is on die?</h2>
          <img width="50%" class="simple" src="images/popt/pLDBDAIaeFFrBEdN.large.jpeg">
          <br>
          <small>Image source <a href="http://www.chipworks.com">ChipWorks</a></small>
        </section> -->

        <section>
          <h2>Key architecture families</h2>
          <ul>
            <li><strong>RISC</strong> - Reduced Instruction Set Computer</li>
            <li><strong>CISC</strong> - Complex Instruction Set Computer</li>
            <li><strong>VLIW</strong> - Very Long Instruction Word</li>
            <li><strong>Vector</strong> architecture</li>
          </ul>
        </section>

        <section>
          <section>
            <h2>CISC</h2>
            <b>Complex Instruction Set Computer</b>
            <ul>
              <li><b>Designed in the 1970s</b> which was a time where transistors were expensive while compilers
              were naive. Additionally, instruction packaging was the main concern due to shortage of memory.</li>
              <li><b>The goal</b> was to define an instruction set that allows high level language constructs
              be translated into <strong>as few assembly language instructions as possible</strong>,
              improving performance as well as code density.</li>
              <li><b>Examples</b> are VAX, x86, <b>AMD64</b>.</li>
              <li><b>Latency-oriented architecture</b>.</li>
            </ul>
          </section>

          <section>
            <h2>CISC</h2>
            <ul>
              <li><b>Heritage</b>
                <ul>
                  <li><i>instructions access memory, a plenty of addressing modes</i>,</li>
                  <li>many instruction families and a <i>very rich ISA</i>,</li>
                  <li>consequently, <i><strong>complicated instruction decoding</strong></i> logic.</li>
                  <li>Moreover, a <i>few registers are available</i> for programmers.</li>
                </ul>
              </li>
              <li><b>Nowadays</b>
                <ol>
                  <li>CISC instructions are typically broken down into the lower level instructions (&mu;code) which
                  are much easy to pipeline and process in a power efficient fashion.</li>
                  <li>Transistors are spent to cache hierarchies, out-of-order execution, large <abbr title="reorder buffers">RB</abbr> and
                   speculation to eliminate stalls.</li>
                   <li>Symmetric multi-processing.</li>
                </ol>
              </li>
            </ul>
          </section>
        </section>

        <section>
          <section>
            <h2>RISC</h2>
            <b>Reduced Instruction Set Computer</b>
            <ul>
              <li><b>Designed in the 1980s</b> which was a time there <abbr >IPL</abbr> was the most concern.</li>
              <li><b>The goal</b> was to decrease the number of clocks per instruction (CPI) while pipeline instructions
              as much as possible employing hardware to help with it. Uniform ISA, pipelining and large register file
              is a must-have.</li>
              <li><b>Examples</b> are <b>MIPS</b>, <b>ARM</b>, <b>PowerPC</b>.</li>
              <li><b>Latency-oriented architecture</b>.</li>
            </ul>
          </section>

          <section>
            <h2>RISC</h2>
            <ul>
              <li><b>Heritage</b>
                <ul>
                  <li>Relatively few instructions, all are the same length.</li>
                  <li>Only load and store instructions access memory.</li>
                  <li>Large resister file than typical CISC processors have.</li>
                  <li>No &mu;code</li>
                </ul>
              </li>
              <li><b>Nowadays</b>
                Most architectures that comes from RISC are called <b>Load-Store architectures</b>, while may employ
                &mu;ops. They combine concepts of a classic RISC with usage of modern hardware enhancements:<br/>
                   <ol>
                    <li>deep pipelines, multi-cycle instructions,</li>
                    <li>out-of-order execution,</li>
                    <li>speculation.</li>
                  </ol>
                </li>
              </ul>
          </section>
        </section>

        <section>
          <h2>The Hardware/Software gap</h2>
          <ul>
            <li>Compiler
              <ul>
                <li>analyzes control flow, analyzes dependency</li>
                <li>schedules instructions</li>
                <li>maps variables to limited register set</li>
              </ul>
            </li>
            <li>Hardware
              <ul>
                <li>analyzes control flow, analyzes dependency</li>
                <li>schedules instructions</li>
                <li>remaps ISA register to large internal register set</li>
              </ul>
            </li>
          </ul>
        </section>

        <section>
          <section>
            <h2>VLIW</h2>
            <b>Very Long Instruction Word</b>
            <ul>
              <li><b>Designed in the 1980s</b> which was a time there IPL was the most concern.</li>
              <li><b>The goal</b> was to pipeline instructions as much as possible employing software to help with it
              reducing complexity of the hardware.</li>
              <li><b>Example</b> is Intel­HP Itanium.</li>
              <li><b>Throughput-oriented architecture</b></li>
            </ul>
          </section>

          <section>
            <h2>VLIW</h2>
            <ul>
              <li><b>Heritage</b>
                <ul>
                  <li>Software determines which instructions can be performed in parallel,</li>
                  <li>bundles this information and the instructions,</li>
                  <li>and passes the <b>bundle</b>(word) to the hardware.</li>
                  <li>No data dependencies between instructions in a bundle.</li>
                  <li>Each operation in a word assigned to specific issue slot (dedicated FU).</li>
                </ul>
              </li>
            </ul>
          </section>

          <section>
            <h2>VLIW</h2>
            <ul>
              <li><b>Nowadays</b>
              <ul>
                <li>hardly any generic processor implements VLIW
                <ul>
                  <li>brunchy nature of production codes (in contrast to HPC or scientific codes),</li>
                  <li>need to follow binary compatibility across the &mu;architecture families.</li>
                </ul></li>
                <li>Whereas architecture is widely adopted for programmable co-processors where shrink in power consumption
              without lose of performance is crucial (DSP, GPU).</li>
              </ul>

            </ul>
          </section>
        </section>

        <section>
          <section>
            <h2>Vector Processors</h2>
            <ul>
              <li><b>First introduced in 1976</b> and dominated for HPC in the 1980s because of high instruction
              throughput.</li>
              <li><b>The goal</b> was to perform operations on vectors of data exposing DLP to increase instruction
              throughput. Vector pipelining is also called chaining.</li>
              <li><b>Example</b> is Cray</li>
              <li><b>Throughput-oriented architectures.</b></li>
            </ul>
          </section>

          <section>
            <h2>Vector Processors</h2>
            <ul>
              <li><b>Heritage</b>
                <ul>
                  <li>Process the data in vectors, each element in a vector (lane) is independent on any other.</li>
                  <li>Deep pipelines, wide execution units, not necessary the same width as size (batch length)
                  if vector in elements (vector length)</li>
                  <li>Most efficient for simple memory patterns, but getter/scatter is usually possible too</li>
                  <li>Wide memory interfaces to saturate execution units</li>
                  <li>Large vector register file, cache is not a strict requirement and absent for classical vector
                  processors.</li>
                </ul>
              </li>
              <br>
            </ul>
          </section>

          <section>
            <h2>Vector Processors</h2>
            <ul>
              <li><b>Nowadays</b>
              <ul>
                <li>They aren't used in generic processors design, but used as a co-processors for
                a specific workloads: HPC, multimedia, precursors of most designs of modern GPUs.</li>
                <li>Vector pipes with short vector length (8-16 bytes) called SIMD units are widely integrated
                in modern general purpose processors to accelerate most demanding loops.</li>
            </ul>
          </section>
        </section>

        <section>
          <section>
            <h2>Why is it doing to be <strike>RISC</strike> Load/Store?</h2>
            <ol>
              <li><b>Simple fixed-width instructions &amp; few addressing modes</b>
                <ul>
                  <li>Instruction fetch is cache-efficient, branches are aligned.</li>
                  <li>Simple hardware logic &#8594; power efficient chips.</li>
                  <li>Drive a higher clock rate.</li>
                </ul>
              </li>
              <li><b>Concise ISA with orthogonal functionality</b>
                <ul>
                  <li>Complex instructions are ignored by compilers due to semantic gap &#8594;
                  simple instructions simplify scheduling.</li>
                  <li>Complex addressing lead either to variable length instructions or big instruction size
                   &#8594; inefficient decoding and scheduling as well as alignment issues.</li>
                </ul>
              </li>
              <li><b>Large register set</b>
                <ul>
                  <li>Expose possible instruction parallelism to the compiler.</li>
                </ul>
              </li>
            </ol>
          </section>
        </section>

        <section>
          <h2>Latest trends</h2>
          The newest trend is providing RISC-based ISA, but construct VLIW instructions on fry during
          instruction fetch, which was already used for Denver &mu;architecture.
        </section>

        <section>
          <h2>Summary</h2>
            <ul style="width: 100%">
              <li></li>
            </ul>
        </section>

        <section>
          <h1>THE END</h1>
          <img alt="The end" class="simple" src="images/popt/infinity.png">
          <h4><a href="https://github.com/cuda-geek">Marina Kolpakova</a> / 2015-2016</h4>
        </section>
          </div>
        </div>

        <script src="lib/js/head.min.js"></script>
        <script src="js/reveal.js"></script>

        <script>

            // Full list of configuration options available at:
            // https://github.com/hakimel/reveal.js#configuration
            Reveal.initialize({
                controls: true,
                progress: true,
                history: true,
                center: false,
                slideNumber: true,

                // parallaxBackgroundImage: "https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg",
                // parallaxBackgroundSize: "2100px 900px",
                // parallaxBackgroundHorizontal: 200,
                // parallaxBackgroundVertical: 50,

                transition: 'slide', // none/fade/slide/convex/concave/zoom

                // Optional reveal.js plugins
                dependencies: [
                    { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
                    { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: 'plugin/zoom-js/zoom.js' , async: true  },
                    { src: 'plugin/notes/notes.js', async: true }
                ]
            });

        </script>

    </body>
</html>
